# Basic Lexer

This project implements a lexer (also known as a tokenizer or scanner) in Python. The lexer's primary purpose is to read source code from a programming language and break it down into a series of tokens that can be used by a parser to construct an abstract syntax tree (AST).

## Features

- Tokenizes a predefined set of tokens including identifiers, keywords, literals (strings, numbers), and operators.
- Supports both single-character and multi-character operators.
- Recognizes and ignores comments in the source code.
- Handles lexical errors with informative messages.

## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes.

### Prerequisites

- Python 3.8 or newer

### Installing

Clone the repository to your local machine:

```bash
git clone https://github.com/mattpark01/basic_lexer.git
```
